<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ChatGPT Project Critical Discussion</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header>
        <h1>Ethics of ChatGPT </h1>
    </header>

    <nav>
        <ul>
            <li><a href="index.html">Introduction</a></li>
            <li><a href="examples.html">Real World Examples</a></li>
            <li><a href="ethical-anylsis.html">Ethics</a></li>
             <li><a href="stakeholders.html">Stakeholders</a></li>
             <li><a href="citations.html">Sources</a></li>
        </ul>
    </nav>

 <main>
    <section>
        <h2>Ethical Lenses Used in Analysis</h2>
        <p>In evaluating ChatGPT, we applied three foundational ethical frameworks to understand its broader societal and moral implications:</p>

        <h3>1. Utilitarianism</h3>
        <p><strong>Focus:</strong> Actions are judged based on their consequences specifically whether they maximize overall happiness or well being.</p>
        <p><strong>Application:</strong> ChatGPT enhances productivity across sectors such as education, business, and software development by automating routine tasks. This can lead to time savings, improved efficiency, and broader access to knowledge. However, these gains come with tradeoffs, such as the displacement of workers in content writing, customer service, and even programming. The utilitarian perspective compels us to weigh these widespread benefits against the harm caused to affected workers (Floridi & Cowls, 2021).</p>

        <h3>2. Deontological Ethics</h3>
        <p><strong>Focus:</strong> Actions should be guided by duty, moral rules, and principles, regardless of the consequences.</p>
        <p><strong>Application:</strong> From a deontological viewpoint, developers and companies have a moral responsibility to prevent the misuse of AI technologies like ChatGPT. Even if imposing strict safeguards or transparency measures reduces short term profits or slows innovation, it aligns with the ethical duty to uphold fairness, protect users from harm, and avoid enabling unethical behavior, such as cheating or the spread of misinformation (Moor, 2006).</p>

        <h3>3. Virtue Ethics</h3>
        <p><strong>Focus:</strong> Ethical behavior stems from cultivating virtues such as honesty, integrity, responsibility, and wisdom.</p>
        <p><strong>Application:</strong> Using ChatGPT in education or professional contexts should encourage responsible and honest behavior. For instance, students can use the tool to support their understanding of topics not to plagiarize. Similarly, businesses should use AI generated content transparently. This lens emphasizes not just what we do with technology, but the kind of people and society we become through its use (Brey, 2012).</p>

        <p>These ethical lenses provide a multidimensional perspective, helping us assess both short term conveniences and the long term societal impact of generative AI tools.</p>
    </section>

    <section>
        <h2>Analysis and Social Implications</h2>
        <p>Beyond theoretical analysis, we considered key real world concerns associated with ChatGPT:</p>
        <ul>
            <li><strong>Job Displacement:</strong> ChatGPT is increasingly used in roles traditionally held by humans such as customer service agents, writers, and junior developers. This automation threatens employment in creative and technical fields, raising economic and ethical concerns about fair labor transitions (Brynjolfsson & McAfee, 2014).</li>
            <li><strong>Bias and Misinformation:</strong> Because ChatGPT is trained on vast datasets that may contain historical and cultural biases, it can unintentionally reinforce stereotypes or generate inaccurate responses. In sensitive areas like healthcare or politics, this poses serious risks to users and public discourse (Bender et al., 2021).</li>
            <li><strong>Overreliance:</strong> As users become more accustomed to AI generated responses, there is a risk of diminished critical thinking and independent judgment. Overdependence on AI for decision making especially in education or mental health contexts can hinder personal development and lead to misuse.</li>
            <li><strong>Accountability:</strong> One of the most pressing ethical questions is who is responsible when AI gives harmful or misleading advice? Unlike humans, AI lacks agency. Determining accountability whether it lies with the developers, users, or platforms is an ongoing challenge in AI governance.</li>
        </ul>
        <p>These issues are particularly difficult to regulate due to the rapid pace of AI development and widespread adoption. Without clear ethical guidelines and accountability mechanisms, society risks long term harm despite short term benefits.</p>
    </section>
</main>


    <footer>
        <p>&copy;IT-304 Final Project</p>
    </footer>
</body>
</html>
